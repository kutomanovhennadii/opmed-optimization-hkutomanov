\## 3.2.3a - Modeling Configuration Extension for Hyperparameter Tuning



\### Purpose

This optional submodule extends the base configuration system to support model-level hyperparameter tuning.  

It defines additional parameters controlling the structure and behavior of the CP-SAT model built by ModelBuilder.  

During tuning, these parameters can be varied automatically by orchestration tools such as Airflow or MLflow while preserving full reproducibility.



---



\### Context

The base configuration (`Config`) in section 3.2.1 focuses on fixed operational limits (shift length, room count, buffer, etc.).  

However, to explore model variants and solver strategies, the tuning system must be able to:

\- change modeling behaviors (use of buffers, symmetry breaking, optional constraints),

\- adjust objective weights,

\- experiment with discretization and branching strategies,

\- and record each configuration as a reproducible experiment.



This extension provides the structured interface required for those operations.



---



\### Function

The extension acts as a lightweight adapter around the `Config` class, introducing a nested section `modeling:`  

and utility helpers for preparing per-run configurations (e.g., `config\_run.yaml`).



---



\### Data Model

class ModelingParams(BaseModel):

buffer: float = 0.25

enforce\_utilization\_constraint: bool = True

objective\_weights: dict = {"alpha": 10.0, "beta": 1.0}

use\_lns: bool = False

branching\_priority\_mode: str = "INTERVAL\_FIRST"

time\_unit: float = 0.0833 # 5 minutes

use\_symmetry\_breaking: bool = False

allow\_room\_preassignment: bool = True





These parameters are grouped under `cfg.modeling` inside the global configuration object.



Example structure inside YAML:

modeling:

buffer: 0.30

enforce\_utilization\_constraint: true

objective\_weights:

alpha: 8.0

beta: 1.2

use\_lns: true

branching\_priority\_mode: "COST\_FIRST"

time\_unit: 0.0833

use\_symmetry\_breaking: true





---



\### Contracts



\*\*Preconditions\*\*

\- Base `Config` is valid and loaded.

\- All numeric fields are positive; `objective\_weights` contain non-negative floats.

\- Unknown keys in `modeling:` section are ignored or raise `ConfigError` depending on strict mode.



\*\*Postconditions\*\*

\- Returns a `Config` object with an embedded `modeling` namespace.

\- `cfg\_hash` computed from the entire effective configuration is stored in `metadata.cfg\_hash` within the ModelBuilder output.

\- All tuning parameters are visible to experiment tracking (MLflow, Airflow, etc.).



\*\*Errors\*\*

\- `ConfigError`: invalid or missing fields, wrong types, or negative numeric values.



---



\### Integration



| Stage | Module | Interaction |

|--------|---------|-------------|

| Configuration Load | DataLoader | Parses `modeling:` block and attaches to Config |

| Model Construction | ModelBuilder | Reads `cfg.modeling` for optional constraints and objectives |

| Hyperparameter Tuning | Airflow / MLflow | Writes temporary `config\_run.yaml` with modified modeling parameters |

| Logging | Metrics \& Logger | Stores `cfg\_hash` and modeling options in metrics.json |



---



\### Example of a Per-Run Configuration File

run\_id: exp\_042

inherit\_from: base\_config.yaml



modeling:

buffer: 0.30

objective\_weights:

alpha: 8.0

beta: 1.2

use\_lns: true

branching\_priority\_mode: "COST\_FIRST"



solver:

num\_workers: 8

max\_time\_in\_seconds: 60





Each experiment run creates its own configuration file (`config\_run.yaml`) and logs its SHA256 hash to `metrics.json` for deterministic reproduction.



---



\### Summary

The Modeling Configuration extension bridges ModelBuilder and the hyperparameter tuning framework.  

It provides a controlled and traceable way to manipulate model-level parameters (buffers, objectives, constraints, and discretization)  

without modifying the source code, ensuring repeatable and auditable optimization experiments.



