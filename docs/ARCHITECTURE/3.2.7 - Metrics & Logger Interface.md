\## 3.2.7 - Metrics \& Logger Interface



\### Purpose

The Metrics \& Logger module aggregates solver results and produces standardized numerical and textual outputs.

It ensures consistent reporting of key metrics and logging across all runs, compatible with ADR-006.

The module serves as the final stage in the optimization pipeline, enabling reproducibility and experiment tracking.



---



\### Function Signatures

collect\_metrics(result: SolveResult, cfg: Config) -> MetricsDict

write\_metrics(metrics: dict, out\_path: Path) -> Path





---



\### Contracts



\*\*Preconditions\*\*

\- `result` is a valid SolveResult object containing fields: status, objective, assignments, metrics, logs.

\- `cfg` contains valid configuration data (solver parameters, time limits, seed).

\- `out\_path` is an existing directory with write permission.



\*\*Postconditions\*\*

\- `collect\_metrics` returns a dictionary (`MetricsDict`) with all required numeric fields.

\- `write\_metrics` writes the dictionary to `metrics.json` (UTF-8 encoded JSON).

\- The resulting JSON conforms to the schema defined in ADR-006.

\- `metrics.json` and `solver.log` are located in the run's output directory.

\- All numeric values are floats; strings are UTF-8 encoded.

\- Timestamps follow ISO-8601 format.



\*\*Errors\*\*

\- `IOError`: output path not writable or file write failure.

\- `ValidationError`: missing or invalid metric fields.

\- `TypeError`: incompatible data types in metrics.



---



\### MetricsDict Schema

Required fields:



| Key | Type | Description |

|------|------|-------------|

| timestamp | str (ISO-8601) | Time of metric creation |

| solver\_status | str | One of \[INFEASIBLE, FEASIBLE, OPTIMAL, UNKNOWN] |

| total\_cost | float | Final objective value |

| utilization | float | Σ(duration\_surgeries) / Σ(cost\_anesthetists) |

| runtime\_sec | float | Solver wall-clock time |

| num\_anesthetists | int | Number of active anesthesiologists |

| num\_workers | int | Number of solver threads |

| seed | int | Random seed used |

| solver.engine | str | Solver type (e.g., CP-SAT) |

| solver.version | str | Version string of OR-Tools |

| config\_hash | str | SHA256 hash of the configuration used |



Optional extensions:

\- `valid` (bool): result validity from Validator.

\- `num\_violations` (int): number of detected constraint violations.

\- `plot\_path` (str): relative path to saved PNG visualization.



---



\### Example metrics.json

{

"timestamp": "2025-10-30T14:45:00",

"solver\_status": "OPTIMAL",

"total\_cost": 184.5,

"utilization": 0.83,

"runtime\_sec": 21.6,

"num\_anesthetists": 14,

"num\_workers": 8,

"seed": 42,

"solver": {

"engine": "CP-SAT",

"version": "9.10"

},

"config\_hash": "e3f1a5b2c71a...",

"valid": true,

"num\_violations": 0,

"plot\_path": "solution\_plot.png"

}





---



\### Logging

A complementary text log file (`solver.log`) must be written alongside metrics.json.

Each entry contains a timestamp, log level, and message, formatted as:



\[timestamp] \[LEVEL] \[event\_message]



Example:

\[2025-10-30 14:31:04] INFO Solver started (workers=8, seed=42)

\[2025-10-30 14:31:25] INFO Status: FEASIBLE Objective=185.0 Runtime=21.6s

\[2025-10-30 14:31:31] INFO Status: OPTIMAL Objective=184.5

\[2025-10-30 14:31:32] INFO Metrics written to metrics.json





---



\### Integration

\- Executed immediately after Optimizer, before Validator or Visualizer.

\- Writes metrics and logs into `data/output/run\_<timestamp>/`.

\- Validator may append validation results into the same `metrics.json`.

\- MLflow and CI/CD pipelines read metrics for experiment tracking and regression checks.



---



\### Summary

The Metrics \& Logger interface guarantees reproducible and standardized reporting of solver outcomes.

It consolidates key performance metrics, ensures consistent formatting across all runs,

and provides both human-readable (`solver.log`) and machine-readable (`metrics.json`) outputs in compliance with ADR-006.
